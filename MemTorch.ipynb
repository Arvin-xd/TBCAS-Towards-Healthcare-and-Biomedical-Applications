{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Cropped APS Images and Raw EMG Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import wget\n",
    "import zipfile\n",
    "from zipfile import ZipFile\n",
    "\n",
    "\n",
    "relax21_cropped_aps = 'https://zenodo.org/record/3663616/files/relax21_cropped_aps.zip'\n",
    "relax21_raw_emg = 'https://zenodo.org/record/3663616/files/relax21_raw_emg.zip'\n",
    "data_directory = 'data'\n",
    "data_downloaded = False\n",
    "if not os.path.isdir(data_directory):\n",
    "    os.mkdir(data_directory)\n",
    "\n",
    "if not [f for f in os.listdir(data_directory) if not f.startswith('.')] == []:\n",
    "    data_downloaded = True\n",
    "\n",
    "if data_downloaded == False:\n",
    "    try:\n",
    "        if not path.isfile('relax21_cropped_aps.zip'):\n",
    "            wget.download(relax21_cropped_aps, 'relax21_cropped_aps.zip')\n",
    "     \n",
    "        if not path.isfile('relax21_raw_emg.zip'):\n",
    "            wget.download(relax21_raw_emg, 'relax21_raw_emg.zip')\n",
    "\n",
    "        relax21_cropped_aps_zip = ZipFile('relax21_cropped_aps.zip', 'r')\n",
    "        relax21_cropped_aps_zip.extractall('data')\n",
    "        relax21_cropped_aps_zip.close()\n",
    "        relax21_raw_emg_zip = ZipFile('relax21_raw_emg.zip', 'r')\n",
    "        relax21_raw_emg_zip.extractall('data')\n",
    "        relax21_raw_emg_zip.close() \n",
    "    except Exception as e:\n",
    "        print('Exception: %s raised. Failed to setup environment.' % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Cropped APS Images and Raw EMG Data and Extract Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import Person, analyze\n",
    "from utils import Person, analyze, corrections\n",
    "import torch\n",
    "\n",
    "\n",
    "classes = ['pinky', 'elle', 'yo', 'index', 'thumb']\n",
    "classes_dict = {'pinky': 0, 'elle': 1, 'yo': 2, 'index': 3, 'thumb': 4}\n",
    "classes_inv = {v: k for k, v in classes_dict.items()}\n",
    "crop_path = 'data/img_cropped/'\n",
    "emg_dir = 'data/EMG/'\n",
    "\n",
    "def load_emg_dataset():\n",
    "    subjects = {}\n",
    "    names = sorted([name for name in os.listdir(emg_dir) if \"emg\" in name])\n",
    "    for name in names:\n",
    "        _emg = np.load(emg_dir + '{}'.format(name)).astype('float32')\n",
    "        _ann = np.concatenate([np.array(['none']), np.load(emg_dir + '{}'.format(name.replace(\"emg\", \"ann\")))[:-1]])\n",
    "        subjects[\"_\".join(name.split(\"_\")[:2])] = Person(name.split(\"_\")[0], _emg, _ann, classes=classes)\n",
    "\n",
    "    print(\"Data Loaded! {} Sessions\".format(len(subjects.keys())))\n",
    "    for name, data in subjects.items():\n",
    "        for _class in classes:\n",
    "            _annotation = np.float32(data.ann == _class)\n",
    "            derivative = np.diff(_annotation) / 1.0\n",
    "            begins = np.where(derivative == 1)[0]\n",
    "            ends = np.where(derivative == -1)[0]\n",
    "            for b, e in zip(begins, ends):\n",
    "                _trials = data.emg[b:e]\n",
    "                data.trials[_class].append(_trials)\n",
    "                data.begs[_class].append(b)\n",
    "                data.ends[_class].append(e)\n",
    "                \n",
    "    print(\"Done sorting trials!\")\n",
    "    X_EMG = []\n",
    "    Y_EMG = []\n",
    "    SUB_EMG = []\n",
    "    SES_EMG = []\n",
    "    TRI_EMG = []\n",
    "    for name, data in subjects.items():\n",
    "        for gesture in classes:\n",
    "            for trial in range(5):\n",
    "                X_EMG.append(data.trials[gesture][trial])\n",
    "                Y_EMG.append(classes_dict[gesture])\n",
    "                SUB_EMG.append(int(name[7:9]))\n",
    "                SES_EMG.append(int(name[17:19]))\n",
    "                TRI_EMG.append(trial)\n",
    "\n",
    "    X_EMG = np.array(X_EMG)\n",
    "    Y_EMG = np.array(Y_EMG)\n",
    "    SUB_EMG = np.array(SUB_EMG)\n",
    "    SES_EMG = np.array(SES_EMG)\n",
    "    TRI_EMG = np.array(TRI_EMG)\n",
    "    return X_EMG, SUB_EMG, SES_EMG, TRI_EMG, Y_EMG\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.144])\n",
    "\n",
    "def load_img_dataset():\n",
    "    all_frames = [i for i in sorted(os.listdir(crop_path)) if 'tiff' in i]\n",
    "    Y_IMG = np.array([classes_dict[i.split('_')[2]] for i in sorted(os.listdir(crop_path)) if 'tiff' in i])\n",
    "    SUB_IMG = np.array([int(i[7:9]) for i in sorted(os.listdir(crop_path)) if 'tiff' in i])\n",
    "    SES_IMG = np.array([int(i[17:19]) for i in sorted(os.listdir(crop_path)) if 'tiff' in i])\n",
    "    TRI_IMG = np.array([int(i.split('_')[3]) for i in sorted(os.listdir(crop_path)) if 'tiff' in i])\n",
    "    IDX_IMG = np.array([int(i.split('_')[4].split('.')[0]) for i in sorted(os.listdir(crop_path)) if 'tiff' in i])\n",
    "    IDX_IMG = np.array(IDX_IMG)\n",
    "    Y_IMG = np.array(Y_IMG)\n",
    "    SUB_IMG = np.array(SUB_IMG)\n",
    "    SES_IMG = np.array(SES_IMG)\n",
    "    TRI_IMG = np.array(TRI_IMG)\n",
    "    X_IMG = np.array([rgb2gray(plt.imread(crop_path + f))[::-1] for f in all_frames])\n",
    "    X_IMG = np.array(X_IMG)\n",
    "    return X_IMG, SUB_IMG, SES_IMG, TRI_IMG, Y_IMG\n",
    "\n",
    "def sync_datasets(EMG, IMG, frame_len=0.2, frame_step=0.1):\n",
    "    X_EMG, SUB_EMG, SES_EMG, TRI_EMG, Y_EMG = EMG\n",
    "    X_IMG, SUB_IMG, SES_IMG, TRI_IMG, Y_IMG = IMG\n",
    "    F_SUB = []\n",
    "    F_SESS = []\n",
    "    F_Y = []\n",
    "    F_IMG = []\n",
    "    F_EMG = []\n",
    "    for subject in range(1, 22):\n",
    "        for session in range(1, 4):\n",
    "            for gesture in range(5):\n",
    "                for trial in range(5):\n",
    "                    fs = corrections['subject{:02}_session0{}'.format(subject, session)]['fs']\n",
    "                    idx_emg = np.logical_and.reduce([SUB_EMG == subject,\n",
    "                                                     SES_EMG == session,\n",
    "                                                     TRI_EMG == trial,\n",
    "                                                     Y_EMG == gesture])\n",
    "                    idx_img = np.logical_and.reduce([SUB_IMG == subject,\n",
    "                                                     SES_IMG == session,\n",
    "                                                     TRI_IMG == trial,\n",
    "                                                     Y_IMG == gesture])\n",
    "                    \n",
    "                    e = X_EMG[idx_emg][0]\n",
    "                    f = X_IMG[idx_img]\n",
    "                    mav = analyze(e, fs=fs, frame_len=frame_len, frame_step=frame_step, feat='MSV', preprocess=False)\n",
    "                    rms = analyze(e, fs=fs, frame_len=frame_len, frame_step=frame_step, feat='RMS', preprocess=False)\n",
    "                    a = np.concatenate([mav, rms], 1)\n",
    "                    mapping = np.arange(len(a)) * len(f) // len(a)\n",
    "                    F_EMG.append(a)\n",
    "                    F_IMG.append(np.stack(f[mapping])) # F_IMG = [np.stack(f[mapping])]\n",
    "                    F_SUB.append(np.ones((len(mapping))) * subject)\n",
    "                    F_SESS.append(np.ones((len(mapping))) * session)\n",
    "                    F_Y.append(np.ones((len(mapping))) * gesture)\n",
    "\n",
    "    F_EMG = np.vstack(F_EMG)\n",
    "    F_IMG = np.vstack(F_IMG)\n",
    "    F_SUB = np.hstack(F_SUB)\n",
    "    F_SESS = np.hstack(F_SESS)\n",
    "    F_Y = np.hstack(F_Y)\n",
    "    return F_EMG, F_IMG, F_SUB, F_SESS, F_Y\n",
    "\n",
    "def create_sets(F_EMG, F_IMG, F_SESS, F_Y, test_ses=1):\n",
    "    x_emg_train = F_EMG[F_SESS != test_ses].astype('float32')\n",
    "    x_emg_test = F_EMG[F_SESS == test_ses].astype('float32')\n",
    "    x_img_train = F_IMG[F_SESS != test_ses].astype('float32')\n",
    "    x_img_test = F_IMG[F_SESS == test_ses].astype('float32')\n",
    "    y_train = F_Y[F_SESS != test_ses]\n",
    "    y_test = F_Y[F_SESS == test_ses]\n",
    "    return x_emg_train, x_img_train, y_train, x_emg_test, x_img_test, y_test\n",
    "\n",
    "def preprocess(x_emg_train, x_img_train, x_emg_test, x_img_test):\n",
    "    data_max = np.max(x_img_train)\n",
    "    data_min = np.min(x_img_train)\n",
    "    for i in range(len(x_img_train)):\n",
    "        x_img_train[i] = (x_img_train[i] - data_min) / (data_max - data_min)\n",
    "        \n",
    "    for i in range(len(x_img_test)):\n",
    "        x_img_test[i] = (x_img_test[i] - data_min) / (data_max - data_min)\n",
    "\n",
    "    data_mean = np.mean(x_img_train)\n",
    "    data_std = np.std(x_img_train) + 1e-15\n",
    "    x_img_train -= data_mean\n",
    "    x_img_train /= data_std\n",
    "    x_img_test -= data_mean\n",
    "    x_img_test /= data_std\n",
    "    data_max = np.max(x_emg_train)\n",
    "    data_min = np.min(x_emg_train)\n",
    "    for i in range(len(x_emg_train)):\n",
    "        x_emg_train[i] = (x_emg_train[i] - data_min) / (data_max - data_min)\n",
    "        \n",
    "    for i in range(len(x_emg_test)):\n",
    "        x_emg_test[i] = (x_emg_test[i] - data_min) / (data_max - data_min)\n",
    "\n",
    "    data_mean = np.mean(x_emg_train)\n",
    "    data_std = np.std(x_emg_train) + 1e-15\n",
    "    x_emg_train -= data_mean\n",
    "    x_emg_train /= data_std\n",
    "    x_emg_test -= data_mean\n",
    "    x_emg_test /= data_std\n",
    "    return x_emg_train, x_img_train, x_emg_test, x_img_test\n",
    "\n",
    "data_dir = 'fold_data'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "    EMG = load_emg_dataset()\n",
    "    IMG = load_img_dataset()\n",
    "    frame_len = 0.2\n",
    "    for test_ses in [1, 2, 3]:\n",
    "        print(test_ses)\n",
    "        F_EMG, F_IMG, F_SUB, F_SESS, F_Y = sync_datasets(EMG, IMG, frame_len=frame_len, frame_step=frame_len / 2)\n",
    "        x_emg_train, x_img_train, y_train, x_emg_test, x_img_test, y_test = create_sets(F_EMG, F_IMG, F_SESS, F_Y, test_ses=test_ses)\n",
    "        x_emg_train, x_img_train, x_emg_test, x_img_test = preprocess(x_emg_train, x_img_train, x_emg_test, x_img_test)\n",
    "        torch.save(torch.tensor(x_emg_train), '%s/fold_%d_x_emg_train.pt' % (data_dir, test_ses - 1)) # EMG training set\n",
    "        torch.save(torch.tensor(x_emg_test), '%s/fold_%d_x_emg_test.pt' % (data_dir, test_ses - 1)) # EMG test set\n",
    "        torch.save(torch.tensor(x_img_train), '%s/fold_%d_x_aps_train.pt' % (data_dir, test_ses - 1)) # APS training set\n",
    "        torch.save(torch.tensor(x_img_test), '%s/fold_%d_x_aps_test.pt' % (data_dir, test_ses - 1)) # APS test set\n",
    "        torch.save(torch.tensor(y_train), '%s/fold_%d_y_train.pt' % (data_dir, test_ses - 1)) # Training set labels\n",
    "        torch.save(torch.tensor(y_test), '%s/fold_%d_y_test.pt' % (data_dir, test_ses - 1)) # Test set labels\n",
    "        del x_emg_train\n",
    "        del x_emg_test\n",
    "        del y_train\n",
    "        del y_test\n",
    "        # Fused APS-EMG training set\n",
    "        x_img_train_a = x_img_train[:, ::2, ::2]\n",
    "        x_img_train_b = x_img_train[:, 1::2, ::2]\n",
    "        x_img_train_c = x_img_train[:, ::2, 1::2]\n",
    "        x_img_train_d = x_img_train[:, 1::2, 1::2]\n",
    "        concat_inp_train = [x_img_train_a.reshape(-1, 400), \n",
    "                            x_img_train_b.reshape(-1, 400), \n",
    "                            x_img_train_c.reshape(-1, 400), \n",
    "                            x_img_train_d.reshape(-1, 400)]\n",
    "        torch.save(torch.tensor(concat_inp_train), '%s/fold_%d_x_concat_train.pt' % (data_dir, test_ses - 1))\n",
    "        del x_img_train_a\n",
    "        del x_img_train_b\n",
    "        del x_img_train_c\n",
    "        del x_img_train_d\n",
    "        del concat_inp_train\n",
    "        # Fused APS-EMG test set\n",
    "        x_img_test_a = x_img_test[:, ::2, ::2]\n",
    "        x_img_test_b = x_img_test[:, 1::2, ::2]\n",
    "        x_img_test_c = x_img_test[:, ::2, 1::2]\n",
    "        x_img_test_d = x_img_test[:, 1::2, 1::2]\n",
    "        concat_inp_test = [x_img_test_a.reshape(-1, 400), \n",
    "                           x_img_test_b.reshape(-1, 400), \n",
    "                           x_img_test_c.reshape(-1, 400), \n",
    "                           x_img_test_d.reshape(-1, 400)]\n",
    "        torch.save(torch.tensor(concat_inp_test), '%s/fold_%d_x_concat_test.pt' % (data_dir, test_ses - 1)) \n",
    "        del x_img_test_a\n",
    "        del x_img_test_b\n",
    "        del x_img_test_c\n",
    "        del x_img_test_d\n",
    "        del concat_inp_test\n",
    "        del x_img_train\n",
    "        del x_img_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the MLP and CNN Network Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MLP_APS_Net(nn.Module):  \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(400, 210)\n",
    "        self.drop1 = nn.Dropout(0.3, inplace=True)\n",
    "        self.fc2 = nn.Linear(210, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop1(x)\n",
    "        return F.softmax(self.fc2(x), dim=1)\n",
    "    \n",
    "class MLP_EMG_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(16, 230)\n",
    "        self.fc2 = nn.Linear(230, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return F.softmax(self.fc2(x), dim=1)    \n",
    "    \n",
    "class MLP_Fused_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "class Conv_APS_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n",
    "        self.drop1 = nn.Dropout(0.25, inplace=True)\n",
    "        self.fc1 = nn.Linear(1152, 512)\n",
    "        self.drop2 = nn.Dropout(0.5, inplace=True)\n",
    "        self.fc2 = nn.Linear(512, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)) ,2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.drop1(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop2(x)\n",
    "        return F.softmax(self.fc2(x), dim=1)    \n",
    "    \n",
    "class Conv_EMG_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(16, 128)\n",
    "        self.drop1 = nn.Dropout(0.5, inplace=True)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.softmax(self.fc3(x))\n",
    "    \n",
    "class Conv_Fused_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import copy\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "class APS(Dataset):\n",
    "    def __init__(self, data, label, expand_dim=True):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.expand_dim = expand_dim\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.expand_dim:\n",
    "            return (torch.unsqueeze(self.data[index], 0), self.label[index].long())\n",
    "        else:\n",
    "            return (self.data[index], self.label[index].long())\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.label.numel()\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "def test(model, test_loader):\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):        \n",
    "        output = model(data.to(device)) \n",
    "        pred = output.data.max(1)[1]\n",
    "        correct += pred.eq(target.to(device).data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    return 100. * float(correct) / float(len(test_loader.dataset))\n",
    "\n",
    "def train(model, epochs, fold, train_loader, test_loader, return_model=False, id=None):\n",
    "    best_accuracy = 0\n",
    "    for epoch in range(0, epochs):\n",
    "        print('Fold: [%d] Epoch: [%d]\\t' % (fold, epoch + 1), end='')\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data.to(device))\n",
    "            loss = criterion(output, target.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        accuracy = test(net, test_loader)\n",
    "        print('%2.2f%%' % accuracy)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = copy.deepcopy(model)\n",
    "            if id is not None:\n",
    "                torch.save(net, 'fold_%d_%s.pt' % (fold, id))\n",
    "            \n",
    "    if return_model:\n",
    "        return best_accuracy, best_model\n",
    "    else:\n",
    "        return best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert all Networks from *Baseline.ipynb*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install memtorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import memtorch\n",
    "from memtorch.mn.Module import patch_model\n",
    "from memtorch.map.Parameter import naive_map\n",
    "from memtorch.bh.crossbar.Program import naive_program\n",
    "from memtorch.bh.nonideality.NonIdeality import apply_nonidealities\n",
    "\n",
    "\n",
    "def det_network_type(network_id):\n",
    "    if 'MLP' in network_id:\n",
    "        return 'MLP'\n",
    "    elif 'Conv' in network_id:\n",
    "        return 'Conv'\n",
    "        \n",
    "def det_input_type(network_id):\n",
    "    if 'APS' in network_id:\n",
    "        return 'APS'\n",
    "    elif 'EMG' in network_id:\n",
    "        return 'EMG'\n",
    "    elif 'Fused' in network_id:\n",
    "        return 'Fused'\n",
    "\n",
    "batch_size = 32\n",
    "reference_memristor = memtorch.bh.memristor.VTEAM\n",
    "# Pt/Hf/Ti device parameters\n",
    "reference_memristor_params = {'time_series_resolution': 1e-6,\n",
    "                              'alpha_off': 1,\n",
    "                              'alpha_on': 3,\n",
    "                              'v_off': 0.5,\n",
    "                              'v_on': -0.53,\n",
    "                              'r_off': 2.5e3,\n",
    "                              'r_on': 100,\n",
    "                              'k_off': 4.03e-8,\n",
    "                              'k_on': -80,\n",
    "                              'd': 10e-9,\n",
    "                              'x_on': 0,\n",
    "                              'x_off': 10e-9}\n",
    "\n",
    "df = pd.DataFrame(columns=['network_type', 'input', 'fold', 'test_set_accuracy'])     \n",
    "for fold in range(3):\n",
    "    y_test = torch.load('fold_data/fold_%d_y_test.pt' % fold)\n",
    "    patched_networks = []\n",
    "    for model in range(4):\n",
    "        net = torch.load('fold_%d_MLP_APS_Net_Model_%d.pt' % (fold, model))\n",
    "        patched_networks.append(patch_model(net,\n",
    "                                          memristor_model=reference_memristor,\n",
    "                                          memristor_model_params=reference_memristor_params,\n",
    "                                          module_parameters_to_patch=[torch.nn.Linear, torch.nn.Conv2d],\n",
    "                                          mapping_routine=naive_map,\n",
    "                                          transistor=True,\n",
    "                                          programming_routine=None))\n",
    "        patched_networks[model].tune_()\n",
    "    \n",
    "    concat_test_output = torch.zeros(y_test.numel(), 5).to(device) \n",
    "    for network_idx, network in enumerate(patched_networks):\n",
    "        inputs = torch.load('fold_data/fold_%d_x_concat_test.pt' % (fold))[network_idx]\n",
    "        for input_idx, input_ in enumerate(inputs):\n",
    "            concat_test_output[input_idx, :] += network(torch.tensor(input_).unsqueeze(0).to(device)).squeeze()\n",
    "            \n",
    "            \n",
    "    concat_test_output_ = torch.argmax(concat_test_output, dim=1)\n",
    "    correct = concat_test_output_.eq(y_test.to(device).data.view_as(concat_test_output_)).cpu().sum()\n",
    "    test_set_accuracy = 100. * float(correct) / float(y_test.numel())\n",
    "    df = df.append({'network_type': 'MLP', 'input': 'APS', 'fold': fold, 'test_set_accuracy': test_set_accuracy}, ignore_index=True)\n",
    "    \n",
    "networks = {}\n",
    "networks['MLP_EMG_Net.pt'] = [MLP_EMG_Net, 'x_emg_train', 'x_emg_test', False]\n",
    "networks['MLP_Fused_Net.pt'] = [MLP_Fused_Net, 'x_fused_train_mlp', 'x_fused_test_mlp', False]\n",
    "networks['Conv_APS_Net.pt'] = [Conv_APS_Net, 'x_aps_train', 'x_aps_test', True]\n",
    "networks['Conv_EMG_Net.pt'] = [Conv_EMG_Net, 'x_emg_train', 'x_emg_test', False]\n",
    "networks['Conv_Fused_Net.pt'] = [Conv_Fused_Net, 'x_fused_train_conv', 'x_fused_test_conv', False]\n",
    "for fold in range(3):\n",
    "    y_test = torch.load('fold_data/fold_%d_y_test.pt' % fold)\n",
    "    for network in networks:\n",
    "        net = torch.load('fold_%d_%s' % (fold, network))\n",
    "        patched_net = patch_model(net,\n",
    "                                  memristor_model=reference_memristor,\n",
    "                                  memristor_model_params=reference_memristor_params,\n",
    "                                  module_parameters_to_patch=[torch.nn.Linear, torch.nn.Conv2d],\n",
    "                                  mapping_routine=naive_map,\n",
    "                                  transistor=True,\n",
    "                                  programming_routine=None)\n",
    "        patched_net.tune_()\n",
    "        test_loader = DataLoader(APS(torch.load('fold_data/fold_%d_%s.pt' % (fold, networks[network][2])), \n",
    "                                 y_test, \n",
    "                                 expand_dim=networks[network][3]), batch_size=batch_size, shuffle=False)\n",
    "        test_set_accuracy = test(patched_net, test_loader)\n",
    "        df = df.append({'network_type': det_network_type(network), 'input': det_input_type(network), 'fold': fold, 'test_set_accuracy': test_set_accuracy}, ignore_index=True)\n",
    "\n",
    "df.to_csv('Converted.csv', index=False)  \n",
    "df = df.sort_values(['network_type','input', 'fold'])\n",
    "frame = df.groupby(['network_type', 'input'])['test_set_accuracy']\n",
    "df['test_set_accuracy_mean'] = frame.transform(np.mean)\n",
    "df['test_set_accuracy_std'] = frame.transform(np.std)\n",
    "df = df.drop(columns=['test_set_accuracy'])\n",
    "df = df.drop_duplicates(subset=['network_type', 'input', 'test_set_accuracy_mean', 'test_set_accuracy_std'], keep='first')\n",
    "df = df.drop(columns=['fold'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device-device Variance Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import memtorch\n",
    "from memtorch.mn.Module import patch_model\n",
    "from memtorch.map.Parameter import naive_map\n",
    "from memtorch.bh.crossbar.Program import naive_program\n",
    "from memtorch.bh.nonideality.NonIdeality import apply_nonidealities\n",
    "\n",
    "\n",
    "reference_memristor = memtorch.bh.memristor.VTEAM\n",
    "df = pd.DataFrame(columns=['network_type', 'input', 'sigma', 'fold', 'test_set_accuracy']) \n",
    "sigma_values = np.linspace(0, 500, 21)\n",
    "\n",
    "for fold in range(3):\n",
    "    y_test = torch.load('fold_data/fold_%d_y_test.pt' % fold)\n",
    "    for sigma in sigma_values:\n",
    "        patched_networks = []\n",
    "        for model in range(4):\n",
    "            net = torch.load('fold_%d_MLP_APS_Net_Model_%d.pt' % (fold, model))\n",
    "            reference_memristor_params = {'time_series_resolution': 1e-6,\n",
    "                                          'alpha_off': 1,\n",
    "                                          'alpha_on': 3,\n",
    "                                          'v_off': 0.5,\n",
    "                                          'v_on': -0.53,\n",
    "                                          'r_off': memtorch.bh.StochasticParameter(2.5e3, std=sigma*2, min=1),\n",
    "                                          'r_on': memtorch.bh.StochasticParameter(100, std=sigma, min=1),\n",
    "                                          'k_off': 4.03e-8,\n",
    "                                          'k_on': -80,\n",
    "                                          'd': 10e-9,\n",
    "                                          'x_on': 0,\n",
    "                                          'x_off': 10e-9}\n",
    "            patched_networks.append(patch_model(net,\n",
    "                                              memristor_model=reference_memristor,\n",
    "                                              memristor_model_params=reference_memristor_params,\n",
    "                                              module_parameters_to_patch=[torch.nn.Linear, torch.nn.Conv2d],\n",
    "                                              mapping_routine=naive_map,\n",
    "                                              transistor=True,\n",
    "                                              programming_routine=None))\n",
    "            patched_networks[model].tune_()\n",
    "            \n",
    "        concat_test_output = torch.zeros(y_test.numel(), 5).to(device) \n",
    "        for network_idx, network in enumerate(patched_networks):\n",
    "            inputs = torch.load('fold_data/fold_%d_x_concat_test.pt' % (fold))[network_idx]\n",
    "            for input_idx, input_ in enumerate(inputs):\n",
    "                concat_test_output[input_idx, :] += network(torch.tensor(input_).unsqueeze(0).to(device)).squeeze()\n",
    "                    \n",
    "        concat_test_output_ = torch.argmax(concat_test_output, dim=1)\n",
    "        correct = concat_test_output_.eq(y_test.to(device).data.view_as(concat_test_output_)).cpu().sum()\n",
    "        test_set_accuracy = 100. * float(correct) / float(y_test.numel())\n",
    "        df = df.append({'network_type': 'MLP', 'input': 'APS', 'sigma': sigma, 'fold': fold, 'test_set_accuracy': test_set_accuracy}, ignore_index=True)\n",
    "\n",
    "networks = {}\n",
    "networks['MLP_EMG_Net.pt'] = [MLP_EMG_Net, 'x_emg_train', 'x_emg_test', False]\n",
    "networks['MLP_Fused_Net.pt'] = [MLP_Fused_Net, 'x_fused_train_mlp', 'x_fused_test_mlp', False]\n",
    "networks['Conv_APS_Net.pt'] = [Conv_APS_Net, 'x_aps_train', 'x_aps_test', True]\n",
    "networks['Conv_EMG_Net.pt'] = [Conv_EMG_Net, 'x_emg_train', 'x_emg_test', False]\n",
    "networks['Conv_Fused_Net.pt'] = [Conv_Fused_Net, 'x_fused_train_conv', 'x_fused_test_conv', False]\n",
    "for sigma in sigma_values:\n",
    "    for fold in range(3):\n",
    "        y_test = torch.load('fold_data/fold_%d_y_test.pt' % fold)\n",
    "        for network in networks:\n",
    "            net = torch.load('fold_%d_%s' % (fold, network))\n",
    "            reference_memristor_params = {'time_series_resolution': 1e-6,\n",
    "                                          'alpha_off': 1,\n",
    "                                          'alpha_on': 3,\n",
    "                                          'v_off': 0.5,\n",
    "                                          'v_on': -0.53,\n",
    "                                          'r_off': memtorch.bh.StochasticParameter(2.5e3, std=sigma*2, min=1),\n",
    "                                          'r_on': memtorch.bh.StochasticParameter(100, std=sigma, min=1),\n",
    "                                          'k_off': 4.03e-8,\n",
    "                                          'k_on': -80,\n",
    "                                          'd': 10e-9,\n",
    "                                          'x_on': 0,\n",
    "                                          'x_off': 10e-9}\n",
    "            patched_net = patch_model(net,\n",
    "                                      memristor_model=reference_memristor,\n",
    "                                      memristor_model_params=reference_memristor_params,\n",
    "                                      module_parameters_to_patch=[torch.nn.Linear, torch.nn.Conv2d],\n",
    "                                      mapping_routine=naive_map,\n",
    "                                      transistor=True,\n",
    "                                      programming_routine=None)\n",
    "            patched_net.tune_()\n",
    "            test_loader = DataLoader(APS(torch.load('fold_data/fold_%d_%s.pt' % (fold, networks[network][2])), \n",
    "                                     y_test, \n",
    "                                     expand_dim=networks[network][3]), batch_size=batch_size, shuffle=False)\n",
    "            test_set_accuracy = test(patched_net, test_loader)\n",
    "            df = df.append({'network_type': det_network_type(network), 'input': det_input_type(network), 'sigma': sigma, 'fold': fold, 'test_set_accuracy': test_set_accuracy}, ignore_index=True)\n",
    "\n",
    "df.to_csv('Variability.csv', index=False)\n",
    "df = df.sort_values(['network_type','input', 'sigma', 'fold'])\n",
    "df['test_set_accuracy'] = pd.to_numeric(df['test_set_accuracy'])\n",
    "frame = df.groupby(['network_type', 'input', 'sigma'])['test_set_accuracy']\n",
    "df['test_set_accuracy_mean'] = frame.transform(np.mean)\n",
    "df['test_set_accuracy_std'] = frame.transform(np.std)\n",
    "df = df.drop(columns=['test_set_accuracy'])\n",
    "df = df.drop_duplicates(subset=['network_type', 'input', 'sigma', 'test_set_accuracy_mean', 'test_set_accuracy_std'], keep='first')\n",
    "df = df.drop(columns=['fold'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device-device Variance and Finite Conductance State Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import memtorch\n",
    "from memtorch.mn.Module import patch_model\n",
    "from memtorch.map.Parameter import naive_map\n",
    "from memtorch.bh.crossbar.Program import naive_program\n",
    "from memtorch.bh.nonideality.NonIdeality import apply_nonidealities\n",
    "\n",
    "\n",
    "reference_memristor = memtorch.bh.memristor.VTEAM\n",
    "df = pd.DataFrame(columns=['network_type', 'input', 'finite_states', 'sigma', 'fold', 'test_set_accuracy']) \n",
    "sigma_values = np.linspace(0, 500, 11)\n",
    "finite_state_values = np.linspace(0, 10, 11)\n",
    "for fold in range(3):\n",
    "    y_test = torch.load('fold_data/fold_%d_y_test.pt' % fold)\n",
    "    for finite_states in finite_state_values:\n",
    "        for sigma in sigma_values:\n",
    "            patched_networks = []\n",
    "            for model in range(4):\n",
    "                net = torch.load('fold_%d_MLP_APS_Net_Model_%d.pt' % (fold, model))\n",
    "                reference_memristor_params = {'time_series_resolution': 1e-6,\n",
    "                                              'alpha_off': 1,\n",
    "                                              'alpha_on': 3,\n",
    "                                              'v_off': 0.5,\n",
    "                                              'v_on': -0.53,\n",
    "                                              'r_off': memtorch.bh.StochasticParameter(2.5e3, std=sigma*2, min=1),\n",
    "                                              'r_on': memtorch.bh.StochasticParameter(100, std=sigma, min=1),\n",
    "                                              'k_off': 4.03e-8,\n",
    "                                              'k_on': -80,\n",
    "                                              'd': 10e-9,\n",
    "                                              'x_on': 0,\n",
    "                                              'x_off': 10e-9}\n",
    "                patched_networks.append(patch_model(net,\n",
    "                                                  memristor_model=reference_memristor,\n",
    "                                                  memristor_model_params=reference_memristor_params,\n",
    "                                                  module_parameters_to_patch=[torch.nn.Linear, torch.nn.Conv2d],\n",
    "                                                  mapping_routine=naive_map,\n",
    "                                                  transistor=True,\n",
    "                                                  programming_routine=None))\n",
    "                if finite_states != 0:\n",
    "                    patched_networks[model] = apply_nonidealities(patched_networks[model],\n",
    "                                                      non_idealities=[memtorch.bh.nonideality.NonIdeality.FiniteConductanceStates],\n",
    "                                                      conductance_states = int(finite_states))\n",
    "                patched_networks[model].tune_()\n",
    "                \n",
    "            concat_test_output = torch.zeros(y_test.numel(), 5).to(device) \n",
    "            for network_idx, network in enumerate(patched_networks):\n",
    "                inputs = torch.load('fold_data/fold_%d_x_concat_test.pt' % (fold))[network_idx]\n",
    "                for input_idx, input_ in enumerate(inputs):\n",
    "                    concat_test_output[input_idx, :] += network(torch.tensor(input_).unsqueeze(0).to(device)).squeeze()\n",
    "        \n",
    "            concat_test_output_ = torch.argmax(concat_test_output, dim=1)\n",
    "            correct = concat_test_output_.eq(y_test.to(device).data.view_as(concat_test_output_)).cpu().sum()\n",
    "            test_set_accuracy = 100. * float(correct) / float(y_test.numel())\n",
    "            df = df.append({'network_type': 'MLP', 'input': 'APS', 'finite_states': finite_states, 'sigma': sigma, 'fold': fold, 'test_set_accuracy': test_set_accuracy}, ignore_index=True)\n",
    "            \n",
    "networks = {}\n",
    "networks['MLP_EMG_Net.pt'] = [MLP_EMG_Net, 'x_emg_train', 'x_emg_test', False]\n",
    "networks['MLP_Fused_Net.pt'] = [MLP_Fused_Net, 'x_fused_train_mlp', 'x_fused_test_mlp', False]\n",
    "networks['Conv_APS_Net.pt'] = [Conv_APS_Net, 'x_aps_train', 'x_aps_test', True]\n",
    "networks['Conv_EMG_Net.pt'] = [Conv_EMG_Net, 'x_emg_train', 'x_emg_test', False]\n",
    "networks['Conv_Fused_Net.pt'] = [Conv_Fused_Net, 'x_fused_train_conv', 'x_fused_test_conv', False]\n",
    "for finite_states in finite_state_values:\n",
    "    for sigma in sigma_values:\n",
    "        for fold in range(3):\n",
    "            y_test = torch.load('fold_data/fold_%d_y_test.pt' % fold)\n",
    "            for network in networks:\n",
    "                net = torch.load('fold_%d_%s' % (fold, network)).to(device)\n",
    "                reference_memristor_params = {'time_series_resolution': 1e-6,\n",
    "                                              'alpha_off': 1,\n",
    "                                              'alpha_on': 3,\n",
    "                                              'v_off': 0.5,\n",
    "                                              'v_on': -0.53,\n",
    "                                              'r_off': memtorch.bh.StochasticParameter(2.5e3, std=sigma*2, min=1),\n",
    "                                              'r_on': memtorch.bh.StochasticParameter(100, std=sigma, min=1),\n",
    "                                              'k_off': 4.03e-8,\n",
    "                                              'k_on': -80,\n",
    "                                              'd': 10e-9,\n",
    "                                              'x_on': 0,\n",
    "                                              'x_off': 10e-9}\n",
    "                patched_net = patch_model(copy.deepcopy(net),\n",
    "                                          memristor_model=reference_memristor,\n",
    "                                          memristor_model_params=reference_memristor_params,\n",
    "                                          module_parameters_to_patch=[torch.nn.Linear, torch.nn.Conv2d],\n",
    "                                          mapping_routine=naive_map,\n",
    "                                          transistor=True,\n",
    "                                          programming_routine=None)\n",
    "                \n",
    "                del net\n",
    "                if finite_states != 0:\n",
    "                    patched_net = apply_nonidealities(copy.deepcopy(patched_net),\n",
    "                                                      non_idealities=[memtorch.bh.nonideality.NonIdeality.FiniteConductanceStates],\n",
    "                                                      conductance_states = int(finite_states))\n",
    "                patched_net.tune_()\n",
    "                test_loader = DataLoader(APS(torch.load('fold_data/fold_%d_%s.pt' % (fold, networks[network][2])), \n",
    "                                         y_test, \n",
    "                                         expand_dim=networks[network][3]), batch_size=batch_size, shuffle=False)\n",
    "                test_set_accuracy = test(patched_net, test_loader)\n",
    "                df = df.append({'network_type': det_network_type(network), 'input': det_input_type(network), 'finite_states': finite_states, 'sigma': sigma, 'fold': fold, 'test_set_accuracy': test_set_accuracy}, ignore_index=True)\n",
    "\n",
    "df.to_csv('Variability_Finite_States.csv', index=False)  \n",
    "df = df.sort_values(['network_type','input', 'finite_states', 'sigma', 'fold'])\n",
    "df['test_set_accuracy'] = pd.to_numeric(df['test_set_accuracy'])\n",
    "frame = df.groupby(['network_type', 'input', 'finite_states', 'sigma'])['test_set_accuracy']\n",
    "df['test_set_accuracy_mean'] = frame.transform(np.mean)\n",
    "df['test_set_accuracy_std'] = frame.transform(np.std)\n",
    "df = df.drop(columns=['test_set_accuracy'])\n",
    "df = df.drop_duplicates(subset=['network_type', 'input', 'finite_states', 'sigma', 'test_set_accuracy_mean', 'test_set_accuracy_std'], keep='first')\n",
    "df = df.drop(columns=['fold'])\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
