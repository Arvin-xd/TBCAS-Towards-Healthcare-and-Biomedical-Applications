{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the MLP and CNN Network Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MLP_APS_Net(nn.Module):  \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(400, 210)\n",
    "        self.drop1 = nn.Dropout(0.3, inplace=True)\n",
    "        self.fc2 = nn.Linear(210, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop1(x)\n",
    "        return F.softmax(self.fc2(x), dim=1)\n",
    "    \n",
    "class MLP_EMG_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(16, 230)\n",
    "        self.fc2 = nn.Linear(230, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return F.softmax(self.fc2(x), dim=1)    \n",
    "    \n",
    "class MLP_Fused_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "class Conv_APS_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n",
    "        self.drop1 = nn.Dropout(0.25, inplace=True)\n",
    "        self.fc1 = nn.Linear(1152, 512)\n",
    "        self.drop2 = nn.Dropout(0.5, inplace=True)\n",
    "        self.fc2 = nn.Linear(512, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)) ,2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.drop1(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop2(x)\n",
    "        return F.softmax(self.fc2(x), dim=1)    \n",
    "    \n",
    "class Conv_EMG_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(16, 128)\n",
    "        self.drop1 = nn.Dropout(0.5, inplace=True)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.softmax(self.fc3(x))\n",
    "    \n",
    "class Conv_Fused_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Serialized *pt* Objects to Equivalent *protxt* and *caffemodel* Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c anaconda caffe -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/xxradon/PytorchToCaffe\n",
    "%cd ~/PytorchToCaffe/\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import pytorch_to_caffe\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "class Ensemble(nn.Module):\n",
    "    def __init__(self, modelA, modelB, modelFused):\n",
    "        super(Ensemble, self).__init__()\n",
    "        self.modelA = modelA\n",
    "        self.modelB = modelB\n",
    "        self.classifier = modelFused\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.modelA(x[0])\n",
    "        x2 = self.modelB(x[1])\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = F.softmax(self.classifier(x), dim=1)\n",
    "        return x\n",
    "    \n",
    "class MLP_APS_Net_Merged(nn.Module):\n",
    "    def __init__(self, model_1, model_2, model_3, model_4):\n",
    "        super().__init__()\n",
    "        self.model_1 = model_1\n",
    "        self.model_2 = model_2\n",
    "        self.model_3 = model_3\n",
    "        self.model_4 = model_4\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.model_1(x[0])\n",
    "        x2 = self.model_2(x[1])\n",
    "        x3 = self.model_3(x[2])\n",
    "        x4 = self.model_4(x[3])\n",
    "        x = torch.stack([x1, x2, x3, x4], dim=1).sum(1)\n",
    "        return x\n",
    " \n",
    "for fold in range(3):\n",
    "    # MLP_APS_Net\n",
    "    MLP_APS_Model_0 = torch.load('../fold_%d_MLP_APS_Net_Model_0.pt' % fold)\n",
    "    MLP_APS_Model_1 = torch.load('../fold_%d_MLP_APS_Net_Model_1.pt' % fold)\n",
    "    MLP_APS_Model_2 = torch.load('../fold_%d_MLP_APS_Net_Model_2.pt' % fold)\n",
    "    MLP_APS_Model_3 = torch.load('../fold_%d_MLP_APS_Net_Model_3.pt' % fold)\n",
    "    net = MLP_APS_Net_Merged(MLP_APS_Model_0, MLP_APS_Model_1, MLP_APS_Model_2, MLP_APS_Model_3).to(device)\n",
    "    input_ = torch.ones((4, 1, 400))\n",
    "    name = 'MLP_APS_Net'\n",
    "    pytorch_to_caffe.trans_net(net, input_, name)\n",
    "    pytorch_to_caffe.save_prototxt('../FPGA/fold_%d_%s.prototxt' % (fold, name))\n",
    "    pytorch_to_caffe.save_caffemodel('../FPGA/fold_%d_%s.caffemodel' % (fold name))\n",
    "\n",
    "    # MLP_Fused_Net\n",
    "    net = Ensemble(net, torch.load('../fold_%d_MLP_EMG_Net.pt' % fold).to(device), torch.load('../fold_%d_MLP_Fused_Net.pt' % fold).to(device))\n",
    "    input_ = [torch.ones(4, 1, 400), torch.ones(1, 16)]\n",
    "    name = 'MLP_Fused_Net'\n",
    "    pytorch_to_caffe.trans_net(net, input_, name)\n",
    "    pytorch_to_caffe.save_prototxt('../FPGA/fold_%d_%s.prototxt' % (fold, name))\n",
    "    pytorch_to_caffe.save_caffemodel('../FPGA/fold_%d_%s.caffemodel' % (fold, name))\n",
    "\n",
    "    # Conv_Fused_Net\n",
    "    net = Ensemble(torch.load('../fold_%d_Conv_APS_Net.pt' % fold).to(device), \n",
    "                   torch.load('../fold_%d_Conv_EMG_Net.pt' % fold).to(device), \n",
    "                   torch.load('../fold_%d_Conv_Fused_Net.pt' % fold).to(device))\n",
    "    input_ = [torch.ones(1, 1, 40, 40), torch.ones(1, 16)]\n",
    "    name = 'Conv_Fused_Net'\n",
    "    pytorch_to_caffe.trans_net(net, input_, name)\n",
    "    pytorch_to_caffe.save_prototxt('../FPGA/fold_%d_%s.prototxt' % (fold, name))\n",
    "    pytorch_to_caffe.save_caffemodel('../FPGA/fold_%d_%s.caffemodel' % (fold, name))\n",
    "\n",
    "    models = {}\n",
    "    models['MLP_EMG_Net'] = ['MLP_EMG_Net.pt', MLP_EMG_Net, (1, 16)]\n",
    "    models['Conv_APS_Net'] = ['Conv_APS_Net.pt', Conv_APS_Net, (1, 1, 40, 40)]\n",
    "    models['Conv_EMG_Net'] = ['Conv_EMG_Net.pt', Conv_EMG_Net, (1, 16)]\n",
    "    for model in models:\n",
    "        net = torch.load('../fold_%d_%s' % models[model][0]).to(device)\n",
    "        input_ = torch.ones(models[model][2])\n",
    "        pytorch_to_caffe.trans_net(net, input_, model)\n",
    "        pytorch_to_caffe.save_prototxt('../FPGA/fold_%d_%s.prototxt' % (fold, name))\n",
    "        pytorch_to_caffe.save_caffemodel('../FPGA/fold_%d_%s.caffemodel' % (fold, name))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
